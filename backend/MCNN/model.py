"""
Implementacja architektury Multi-Column Convolutional Neural Network (MCNN)
dla problemu zliczania obiekt贸w i generowania map gstoci.

MCNN wykorzystuje r贸wnolege cie偶ki konwolucyjne z filtrami o r贸偶nych rozmiarach
do jednoczesnego wykrywania cech obiekt贸w w r贸偶nych skalach, co czyni model
szczeg贸lnie efektywnym w zliczaniu obiekt贸w o zr贸偶nicowanych rozmiarach.

Autorzy oryginalnej pracy: Zhang et al., "Single-Image Crowd Counting via Multi-Column CNN"
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

class MCNN(nn.Module):
    """
    Multi-Column Convolutional Neural Network do zliczania obiekt贸w.
    
    Architektura skada si z trzech r贸wnolegych cie偶ek konwolucyjnych,
    z kt贸rych ka偶da wykorzystuje filtry o r贸偶nych rozmiarach:
    - branch1: du偶e filtry (9x9, 7x7) do wykrywania du偶ych obiekt贸w
    - branch2: rednie filtry (7x7, 5x5) do obiekt贸w redniej wielkoci
    - branch3: mae filtry (5x5, 3x3) do wykrywania mniejszych obiekt贸w
    
    Wszystkie cie偶ki s nastpnie czone i przetwarzane przez warstw fuzji,
    kt贸ra generuje jednowymiarow map gstoci jako wyjcie.
    """
    def __init__(self):
        """
        Inicjalizacja modelu MCNN z trzema r贸wnolegymi cie偶kami konwolucyjnymi
        o r贸偶nych rozmiarach filtr贸w.
        """
        super(MCNN, self).__init__()

        #  cie偶ka 1: Du偶e filtry - do wykrywania du偶ych obiekt贸w/wzorc贸w
        self.branch1 = nn.Sequential(
            # Warstwa wejciowa: konwersja 3-kanaowego obrazu na 64 mapy cech z filtrem 9x9
            nn.Conv2d(3, 64, kernel_size=9, stride=1, padding=4),  # padding=4 zachowuje wymiary przestrzenne
            nn.ReLU(),  # Nieliniowa aktywacja ReLU
            # Druga warstwa: redukcja do 32 map cech z filtrem 7x7
            nn.Conv2d(64, 32, kernel_size=7, stride=1, padding=3),
            nn.ReLU()
        )

        #  cie偶ka 2: rednie filtry - do wykrywania obiekt贸w redniej wielkoci
        self.branch2 = nn.Sequential(
            # Warstwa wejciowa: konwersja 3-kanaowego obrazu na 64 mapy cech z filtrem 7x7
            nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3),
            nn.ReLU(),
            # Druga warstwa: redukcja do 32 map cech z filtrem 5x5
            nn.Conv2d(64, 32, kernel_size=5, stride=1, padding=2),
            nn.ReLU()
        )

        #  cie偶ka 3: Mae filtry - do wykrywania maych obiekt贸w/szczeg贸贸w
        self.branch3 = nn.Sequential(
            # Warstwa wejciowa: konwersja 3-kanaowego obrazu na 64 mapy cech z filtrem 5x5
            nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=2),
            nn.ReLU(),
            # Druga warstwa: redukcja do 32 map cech z filtrem 3x3
            nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),
            nn.ReLU()
        )

        #  Warstwa fuzji - czy wyniki wszystkich cie偶ek
        self.fuse = nn.Sequential(
            # Redukcja poczonych 96 map cech (32*3) do 64 map z konwolucj 1x1
            nn.Conv2d(96, 64, kernel_size=1),  # konwolucja 1x1 czy informacje z r贸偶nych kana贸w
            nn.ReLU(),
            # Finalna konwersja do pojedynczej mapy gstoci
            nn.Conv2d(64, 1, kernel_size=1)  # Wyjcie: mapa gstoci o wymiarach wejcia
        )

    def forward(self, x):
        """
        Przeprowadza forward pass przez sie MCNN.
        
        Args:
            x (torch.Tensor): Tensor wejciowy o ksztacie [batch_size, 3, height, width]
            
        Returns:
            torch.Tensor: Mapa gstoci o ksztacie [batch_size, 1, height, width]
        """
        # Przetwarzanie obrazu przez trzy r贸wnolege cie偶ki
        b1 = self.branch1(x)  # Ekstrakcja cech z du偶ymi filtrami
        b2 = self.branch2(x)  # Ekstrakcja cech z rednimi filtrami
        b3 = self.branch3(x)  # Ekstrakcja cech z maymi filtrami

        # Poczenie wynik贸w z trzech cie偶ek wzdu偶 wymiaru kana贸w (dim=1)
        # Wynikowy tensor ma wymiar [batch_size, 96, height, width]
        out = torch.cat((b1, b2, b3), dim=1)
        
        # Zastosowanie warstwy fuzji do poczonych map cech
        # Wynikowa mapa gstoci ma wymiar [batch_size, 1, height, width]
        out = self.fuse(out)
        
        return out